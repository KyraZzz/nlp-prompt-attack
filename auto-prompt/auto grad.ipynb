{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12afdcf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cadfd938",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor(2.0, requires_grad=True)\n",
    "b = torch.tensor(3.0, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb4f9f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = a * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8e3f27b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6., grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4b26e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2., requires_grad=True)\n",
      "tensor(3., requires_grad=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(a), print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63f6afea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def c_hook(grad):\n",
    "    print(grad)\n",
    "    return grad + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "717b30ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.hooks.RemovableHandle at 0x7fa71fa8de10>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.register_hook(c_hook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e698a77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.hooks.RemovableHandle at 0x7fa71fa8e770>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.register_hook(lambda grad : print(grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4043473d",
   "metadata": {},
   "outputs": [],
   "source": [
    "c.retain_grad() # save the gradients on the forward and backward graph on intermediate nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efbb6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "c.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1acfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = torch.tensor(4.0, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0286ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "d.register_hook(lambda grad: grad + 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aeed03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "e = c * d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13911734",
   "metadata": {},
   "outputs": [],
   "source": [
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db7e4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "e.retain_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8ba4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "e.register_hook(lambda grad: grad * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e06b09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eaffe46",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyMultiply(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyMultiply, self).__init__()\n",
    "    @staticmethod\n",
    "    def forward(a, b):\n",
    "        return a * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ccd47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_hook(module, grad_input, grad_output):\n",
    "    print('module:', module)\n",
    "    print('grad_input', grad_input)\n",
    "    print('grad_output', grad_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98adf4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_multiply = MyMultiply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1c3266",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_multiply.register_full_backward_hook(backward_hook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981526e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = my_multiply(a, b)\n",
    "c.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ccd536",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4da10c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('roberta-base')\n",
    "model = AutoModelForMaskedLM.from_pretrained('roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0e69ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"A pleasure to watch. <mask> <mask> great.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89583a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_ids = tokenizer.encode(sentence, return_tensors=\"pt\")\n",
    "token_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ffd087",
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_position = (token_ids.squeeze() == tokenizer.mask_token_id).nonzero().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6fb148",
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57b7803",
   "metadata": {},
   "outputs": [],
   "source": [
    "model(token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61d199d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    output = model(token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454cf87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87282593",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_hidden_state = output[0].squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32da2d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acae3545",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_list = []\n",
    "for index, mask_index in enumerate(masked_position):\n",
    "    print(f\"index: {index}, mask_index: {mask_index}\")\n",
    "    mask_hidden_state = last_hidden_state[mask_index]\n",
    "    idx = torch.topk(mask_hidden_state, k = 5, dim=0)[1]\n",
    "    print(f\"idx: {idx}\")\n",
    "    words = [tokenizer.decode(x.item()).strip() for x in idx]\n",
    "    list_of_list.append(words)\n",
    "    print(f\"Mask: {index+1}, Guesses: {words}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912ecc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_guess = \"\"\n",
    "for j in list_of_list:\n",
    "    best_guess = best_guess+\" \"+j[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b62b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03dc7215",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be6c44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sst2 = load_dataset(\"glue\",\"sst2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b16f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_16_val = sst2['validation'][:16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7904170",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_16_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "781abf8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = torch.tensor([[1,2,3],[4,5,6],[7,8,9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8fa7112",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ce9d3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_token_pos = torch.tensor([[2],[1],[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "847ec849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2],\n",
       "        [1],\n",
       "        [0]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigger_token_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ee33d12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b1d35a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = torch.tensor([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6e6536cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids[1] = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7c1b5c36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 9, 3])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "19be3b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "input_ids2 = np.array([4,5,6])\n",
    "input_ids3 = np.array([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb74fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_list = []\n",
    "encoding_list.append(input_ids2)\n",
    "encoding_list.append(input_ids3)\n",
    "np.array(encoding_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "64c7c518",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids0 = torch.stack((input_ids, input_ids2), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bcb6cfa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1, 9, 3]), array([4, 5, 6])]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding_list = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e14260c8",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [2, 3] at entry 0 and [3] at entry 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [36]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_ids2\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [2, 3] at entry 0 and [3] at entry 1"
     ]
    }
   ],
   "source": [
    "torch.stack((input_ids0, input_ids2), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22a1fbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForMaskedLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfeec715",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_hook(module, grad_in, grad_out):\n",
    "    print(f\"grad_out: {grad_out}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3e0357f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForMaskedLM(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (lm_head): RobertaLMHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (decoder): Linear(in_features=768, out_features=50265, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_LM = AutoModelForMaskedLM.from_pretrained(\"roberta-base\")\n",
    "model_LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c04bf2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "84e23575",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = AutoModel.from_pretrained(\"roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d07fd489",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = model.roberta.embeddings.word_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5dc3f6cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.hooks.RemovableHandle at 0x7fa26e866d70>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.register_full_backward_hook(backward_hook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0b3c422",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07cbdbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8415ea91",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"I love this film.\"\n",
    "model_inputs = tokenizer.encode_plus(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "584a2314",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'attention_masks'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m loss \u001b[38;5;241m=\u001b[39m model(model_inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[43mmodel_inputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mattention_masks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m)\n",
      "File \u001b[0;32m/local/scratch-3/yz709/anaconda3/envs/nlp-prompt-attack-env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:233\u001b[0m, in \u001b[0;36mBatchEncoding.__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;124;03mIf the key is a string, returns the value of the dict associated to `key` ('input_ids', 'attention_mask',\u001b[39;00m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;124;03metc.).\u001b[39;00m\n\u001b[1;32m    229\u001b[0m \n\u001b[1;32m    230\u001b[0m \u001b[38;5;124;03mIf the key is an integer, get the `tokenizers.Encoding` for batch item with index `key`.\u001b[39;00m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(item, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 233\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_encodings \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_encodings[item]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'attention_masks'"
     ]
    }
   ],
   "source": [
    "loss = model(model_inputs[\"input_ids\"], model_inputs[\"attention_masks\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f773d950",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(6, 3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cd354665",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.7355,  0.7385,  0.3897,  0.3474],\n",
       "         [-0.3760,  0.1875, -0.8486,  1.9865],\n",
       "         [ 0.6533,  0.9322, -1.0370, -1.0321]],\n",
       "\n",
       "        [[-0.5080,  0.9479, -0.7883,  0.7350],\n",
       "         [-0.6821, -0.7658, -2.5501, -2.4049],\n",
       "         [ 0.5876, -0.0761, -0.3878,  0.5497]],\n",
       "\n",
       "        [[-0.9185, -0.9351,  0.1618, -1.0399],\n",
       "         [ 0.1141, -0.0998,  0.2193, -0.0797],\n",
       "         [ 0.5163, -1.3550,  0.5847, -0.6797]],\n",
       "\n",
       "        [[-0.3077,  0.5037, -0.5051, -0.6428],\n",
       "         [-0.2886, -2.3119,  0.4147,  0.0797],\n",
       "         [-0.1951, -0.4515,  1.8489, -1.6408]],\n",
       "\n",
       "        [[-0.1316, -0.3118,  0.3390,  1.8787],\n",
       "         [-1.0587, -1.0375,  0.0529,  0.3393],\n",
       "         [ 1.7818, -0.9404, -0.3334,  0.1080]],\n",
       "\n",
       "        [[ 0.6194, -1.3400, -2.4347,  1.3792],\n",
       "         [-0.2325,  0.2713,  0.5366,  1.0179],\n",
       "         [-0.3320,  0.3746,  0.4161,  1.1477]]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2e552894",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = torch.tensor([1, 0, 2, 1, 2, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "34343789",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Index tensor must have the same number of dimensions as input tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [44]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgather\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Index tensor must have the same number of dimensions as input tensor"
     ]
    }
   ],
   "source": [
    "torch.gather(x, dim = 0, index = indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "38faf077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(x.size(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3ab9ce68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3760,  0.1875, -0.8486,  1.9865],\n",
       "        [-0.5080,  0.9479, -0.7883,  0.7350],\n",
       "        [ 0.5163, -1.3550,  0.5847, -0.6797],\n",
       "        [-0.2886, -2.3119,  0.4147,  0.0797],\n",
       "        [ 1.7818, -0.9404, -0.3334,  0.1080],\n",
       "        [ 0.6194, -1.3400, -2.4347,  1.3792]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[torch.arange(x.size(0)), indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20fb066",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
