{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "019dcbd0",
   "metadata": {},
   "source": [
    "# Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3758580",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73980eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "411c59f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer, AdamW, AutoConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0ecc82",
   "metadata": {},
   "source": [
    "# Download datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e3dc71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnli_path = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "165f66cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Found cached dataset multi_nli (/home/yz709/.cache/huggingface/datasets/multi_nli/default/0.0.0/591f72eb6263d1ab527561777936b199b714cda156d35716881158a2bd144f39)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49021329e35440568e4a7f335d570ae7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if mnli_path == None:\n",
    "    mnli = load_dataset(\"multi_nli\")\n",
    "    mnli_path = \"./datasets/mnli\"\n",
    "    mnli.save_to_disk(mnli_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3663e374",
   "metadata": {},
   "outputs": [],
   "source": [
    "qnli_path = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f7915d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration SetFit--qnli-324fd6914ad1beff\n",
      "Found cached dataset json (/home/yz709/.cache/huggingface/datasets/SetFit___json/SetFit--qnli-324fd6914ad1beff/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05e1831f180a432c8d4716f84e87de6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if qnli_path == None:\n",
    "    qnli = load_dataset(\"SetFit/qnli\")\n",
    "    qnli_path = \"./datasets/qnli\"\n",
    "    qnli.save_to_disk(qnli_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe49be5",
   "metadata": {},
   "source": [
    "# Inspect datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b43448",
   "metadata": {},
   "source": [
    "## For qnli dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e00543fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text1', 'text2', 'label', 'idx', 'label_text'],\n",
       "        num_rows: 104743\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text1', 'text2', 'label', 'idx', 'label_text'],\n",
       "        num_rows: 5463\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text1', 'text2', 'label', 'idx', 'label_text'],\n",
       "        num_rows: 5463\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qnli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b79a1f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "qnli_train = qnli['train']\n",
    "qnli_test = qnli['test']\n",
    "qnli_val = qnli['validation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41480f7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text1': ['What individual was responsible for law and maintaining order in the county?',\n",
       "  'How much of the gross domestic product was spent on public health in 2004?'],\n",
       " 'text2': ['He was the top civil and military leader of the commandery and handled defense, lawsuits, seasonal instructions to farmers and recommendations of nominees for office sent annually to the capital in a quota system first established by Emperor Wu.',\n",
       "  'Public expenditure health was at 8.9% of the GDP in 2004, whereas private expenditure was at 1.3%.'],\n",
       " 'label': [1, 0],\n",
       " 'idx': [104741, 104742],\n",
       " 'label_text': ['not entailment', 'entailment']}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# label 0 - entailment, label 1 - not entailment\n",
    "qnli_train[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5abbe76c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What individual was responsible for law and maintaining order in the county?',\n",
       " 'How much of the gross domestic product was spent on public health in 2004?']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qnli_train['text1'][-2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcea50ed",
   "metadata": {},
   "source": [
    "## For mnli dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72e1d1e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['promptID', 'pairID', 'premise', 'premise_binary_parse', 'premise_parse', 'hypothesis', 'hypothesis_binary_parse', 'hypothesis_parse', 'genre', 'label'],\n",
       "        num_rows: 392702\n",
       "    })\n",
       "    validation_matched: Dataset({\n",
       "        features: ['promptID', 'pairID', 'premise', 'premise_binary_parse', 'premise_parse', 'hypothesis', 'hypothesis_binary_parse', 'hypothesis_parse', 'genre', 'label'],\n",
       "        num_rows: 9815\n",
       "    })\n",
       "    validation_mismatched: Dataset({\n",
       "        features: ['promptID', 'pairID', 'premise', 'premise_binary_parse', 'premise_parse', 'hypothesis', 'hypothesis_binary_parse', 'hypothesis_parse', 'genre', 'label'],\n",
       "        num_rows: 9832\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "260f7ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnli_train = mnli['train']\n",
    "mnli_val_match = mnli['validation_matched']\n",
    "mnli_val_mismatch = mnli['validation_mismatched']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "341ca12a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['promptID', 'pairID', 'premise', 'premise_binary_parse', 'premise_parse', 'hypothesis', 'hypothesis_binary_parse', 'hypothesis_parse', 'genre', 'label'],\n",
       "    num_rows: 392702\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnli_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b7d8c18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'promptID': 31193,\n",
       " 'pairID': '31193n',\n",
       " 'premise': 'Conceptually cream skimming has two basic dimensions - product and geography.',\n",
       " 'premise_binary_parse': '( ( Conceptually ( cream skimming ) ) ( ( has ( ( ( two ( basic dimensions ) ) - ) ( ( product and ) geography ) ) ) . ) )',\n",
       " 'premise_parse': '(ROOT (S (NP (JJ Conceptually) (NN cream) (NN skimming)) (VP (VBZ has) (NP (NP (CD two) (JJ basic) (NNS dimensions)) (: -) (NP (NN product) (CC and) (NN geography)))) (. .)))',\n",
       " 'hypothesis': 'Product and geography are what make cream skimming work. ',\n",
       " 'hypothesis_binary_parse': '( ( ( Product and ) geography ) ( ( are ( what ( make ( cream ( skimming work ) ) ) ) ) . ) )',\n",
       " 'hypothesis_parse': '(ROOT (S (NP (NN Product) (CC and) (NN geography)) (VP (VBP are) (SBAR (WHNP (WP what)) (S (VP (VBP make) (NP (NP (NN cream)) (VP (VBG skimming) (NP (NN work)))))))) (. .)))',\n",
       " 'genre': 'government',\n",
       " 'label': 1}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnli_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "97c2a49b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'promptID': 37397,\n",
       " 'pairID': '37397e',\n",
       " 'premise': 'How do you know? All this is their information again.',\n",
       " 'premise_binary_parse': '( ( How ( ( ( do you ) know ) ? ) ) ( ( All this ) ( ( ( is ( their information ) ) again ) . ) ) )',\n",
       " 'premise_parse': '(ROOT (S (SBARQ (WHADVP (WRB How)) (SQ (VBP do) (NP (PRP you)) (VP (VB know))) (. ?)) (NP (PDT All) (DT this)) (VP (VBZ is) (NP (PRP$ their) (NN information)) (ADVP (RB again))) (. .)))',\n",
       " 'hypothesis': 'This information belongs to them.',\n",
       " 'hypothesis_binary_parse': '( ( This information ) ( ( belongs ( to them ) ) . ) )',\n",
       " 'hypothesis_parse': '(ROOT (S (NP (DT This) (NN information)) (VP (VBZ belongs) (PP (TO to) (NP (PRP them)))) (. .)))',\n",
       " 'genre': 'fiction',\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnli_train[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6412521",
   "metadata": {},
   "source": [
    "# Preprocess dataset QNLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d3f03942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# roberta-base or roberta-large\n",
    "PLM = \"distilbert-base-uncased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "99464e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_transform.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "model = AutoModel.from_pretrained(PLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f547cc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load tokeniser for the specific model\n",
    "tokeniser = AutoTokenizer.from_pretrained(PLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "64c893b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_config = AutoConfig.from_pretrained(PLM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c20417",
   "metadata": {},
   "source": [
    "### Test the tokeniser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f0ee18a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 384\n",
    "doc_stride = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7d1ed37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = qnli_train[2711]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "598cd1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenised_examples = tokeniser(\n",
    "    example[\"text1\"],\n",
    "    example[\"text2\"],\n",
    "    truncation=\"only_second\",\n",
    "    max_length=max_length,\n",
    "    stride=doc_stride,\n",
    "    return_overflowing_tokens=True,\n",
    "    return_offsets_mapping=True,\n",
    "    padding=\"max_length\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0fd03043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_mapping = tokenised_examples.pop(\"overflow_to_sample_mapping\")\n",
    "sample_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b0b62af3",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 0),\n",
       "  (0, 4),\n",
       "  (5, 9),\n",
       "  (10, 18),\n",
       "  (19, 26),\n",
       "  (27, 35),\n",
       "  (36, 40),\n",
       "  (40, 41),\n",
       "  (0, 0),\n",
       "  (0, 5),\n",
       "  (6, 9),\n",
       "  (10, 14),\n",
       "  (14, 15),\n",
       "  (15, 20),\n",
       "  (21, 24),\n",
       "  (25, 26),\n",
       "  (26, 27),\n",
       "  (27, 28),\n",
       "  (28, 29),\n",
       "  (30, 40),\n",
       "  (41, 48),\n",
       "  (49, 55),\n",
       "  (56, 60),\n",
       "  (60, 61),\n",
       "  (62, 68),\n",
       "  (69, 73),\n",
       "  (73, 74),\n",
       "  (75, 81),\n",
       "  (82, 83),\n",
       "  (83, 84),\n",
       "  (85, 86),\n",
       "  (86, 87),\n",
       "  (88, 92),\n",
       "  (92, 93),\n",
       "  (94, 98),\n",
       "  (99, 106),\n",
       "  (107, 110),\n",
       "  (111, 117),\n",
       "  (118, 119),\n",
       "  (119, 120),\n",
       "  (121, 125),\n",
       "  (125, 126),\n",
       "  (127, 133),\n",
       "  (134, 139),\n",
       "  (140, 148),\n",
       "  (149, 157),\n",
       "  (158, 162),\n",
       "  (162, 165),\n",
       "  (165, 168),\n",
       "  (168, 169),\n",
       "  (170, 176),\n",
       "  (177, 179),\n",
       "  (179, 183),\n",
       "  (183, 186),\n",
       "  (187, 193),\n",
       "  (193, 194),\n",
       "  (195, 198),\n",
       "  (199, 205),\n",
       "  (206, 208),\n",
       "  (208, 210),\n",
       "  (210, 212),\n",
       "  (213, 217),\n",
       "  (217, 218),\n",
       "  (219, 221),\n",
       "  (221, 223),\n",
       "  (223, 226),\n",
       "  (226, 227),\n",
       "  (227, 228),\n",
       "  (229, 234),\n",
       "  (235, 237),\n",
       "  (238, 243),\n",
       "  (243, 244),\n",
       "  (245, 254),\n",
       "  (255, 262),\n",
       "  (263, 268),\n",
       "  (269, 277),\n",
       "  (278, 283),\n",
       "  (284, 288),\n",
       "  (288, 289),\n",
       "  (289, 290),\n",
       "  (291, 298),\n",
       "  (299, 304),\n",
       "  (305, 313),\n",
       "  (314, 317),\n",
       "  (317, 319),\n",
       "  (320, 322),\n",
       "  (322, 326),\n",
       "  (326, 327),\n",
       "  (328, 335),\n",
       "  (336, 345),\n",
       "  (346, 353),\n",
       "  (354, 356),\n",
       "  (356, 358),\n",
       "  (358, 361),\n",
       "  (361, 362),\n",
       "  (363, 369),\n",
       "  (370, 379),\n",
       "  (380, 384),\n",
       "  (385, 389),\n",
       "  (389, 393),\n",
       "  (393, 394),\n",
       "  (395, 398),\n",
       "  (399, 410),\n",
       "  (411, 420),\n",
       "  (421, 425),\n",
       "  (426, 429),\n",
       "  (429, 433),\n",
       "  (434, 440),\n",
       "  (440, 441),\n",
       "  (442, 443),\n",
       "  (443, 444),\n",
       "  (444, 445),\n",
       "  (445, 446),\n",
       "  (447, 454),\n",
       "  (455, 460),\n",
       "  (461, 469),\n",
       "  (470, 475),\n",
       "  (476, 480),\n",
       "  (480, 483),\n",
       "  (483, 485),\n",
       "  (485, 486),\n",
       "  (487, 493),\n",
       "  (494, 497),\n",
       "  (497, 499),\n",
       "  (500, 503),\n",
       "  (504, 512),\n",
       "  (513, 519),\n",
       "  (519, 520),\n",
       "  (521, 522),\n",
       "  (522, 523),\n",
       "  (523, 524),\n",
       "  (524, 525),\n",
       "  (526, 537),\n",
       "  (538, 540),\n",
       "  (541, 546),\n",
       "  (547, 551),\n",
       "  (552, 557),\n",
       "  (557, 558),\n",
       "  (559, 566),\n",
       "  (567, 574),\n",
       "  (574, 575),\n",
       "  (576, 581),\n",
       "  (582, 587),\n",
       "  (587, 588),\n",
       "  (589, 592),\n",
       "  (593, 597),\n",
       "  (598, 602),\n",
       "  (602, 605),\n",
       "  (605, 606),\n",
       "  (607, 614),\n",
       "  (615, 623),\n",
       "  (624, 629),\n",
       "  (629, 630),\n",
       "  (631, 638),\n",
       "  (639, 646),\n",
       "  (647, 650),\n",
       "  (650, 652),\n",
       "  (652, 653),\n",
       "  (654, 657),\n",
       "  (658, 661),\n",
       "  (662, 667),\n",
       "  (667, 668),\n",
       "  (669, 673),\n",
       "  (673, 675),\n",
       "  (675, 682),\n",
       "  (683, 687),\n",
       "  (688, 695),\n",
       "  (695, 696),\n",
       "  (697, 705),\n",
       "  (705, 706),\n",
       "  (707, 713),\n",
       "  (714, 715),\n",
       "  (715, 716),\n",
       "  (717, 718),\n",
       "  (718, 719),\n",
       "  (720, 725),\n",
       "  (726, 729),\n",
       "  (730, 733),\n",
       "  (734, 741),\n",
       "  (741, 742),\n",
       "  (743, 750),\n",
       "  (751, 754),\n",
       "  (755, 756),\n",
       "  (756, 761),\n",
       "  (762, 765),\n",
       "  (765, 766),\n",
       "  (767, 773),\n",
       "  (774, 778),\n",
       "  (778, 779),\n",
       "  (780, 790),\n",
       "  (791, 799),\n",
       "  (800, 807),\n",
       "  (807, 808),\n",
       "  (809, 815),\n",
       "  (815, 816),\n",
       "  (817, 826),\n",
       "  (827, 830),\n",
       "  (831, 840),\n",
       "  (841, 845),\n",
       "  (846, 852),\n",
       "  (852, 853),\n",
       "  (854, 859),\n",
       "  (860, 867),\n",
       "  (867, 868),\n",
       "  (869, 876),\n",
       "  (877, 882),\n",
       "  (882, 883),\n",
       "  (884, 887),\n",
       "  (887, 889),\n",
       "  (890, 892),\n",
       "  (892, 895),\n",
       "  (895, 896),\n",
       "  (896, 897),\n",
       "  (898, 900),\n",
       "  (900, 902),\n",
       "  (902, 906),\n",
       "  (906, 907),\n",
       "  (908, 914),\n",
       "  (914, 915),\n",
       "  (916, 918),\n",
       "  (918, 921),\n",
       "  (922, 928),\n",
       "  (928, 929),\n",
       "  (930, 936),\n",
       "  (937, 944),\n",
       "  (944, 945),\n",
       "  (946, 954),\n",
       "  (955, 963),\n",
       "  (963, 964),\n",
       "  (965, 973),\n",
       "  (974, 979),\n",
       "  (979, 980),\n",
       "  (981, 988),\n",
       "  (989, 991),\n",
       "  (991, 994),\n",
       "  (994, 997),\n",
       "  (997, 998),\n",
       "  (998, 999),\n",
       "  (1000, 1003),\n",
       "  (1003, 1004),\n",
       "  (1005, 1010),\n",
       "  (1010, 1011),\n",
       "  (1012, 1018),\n",
       "  (1019, 1022),\n",
       "  (1023, 1027),\n",
       "  (1027, 1028),\n",
       "  (1029, 1035),\n",
       "  (1036, 1042),\n",
       "  (1042, 1043),\n",
       "  (1044, 1046),\n",
       "  (1046, 1049),\n",
       "  (1049, 1050),\n",
       "  (1051, 1053),\n",
       "  (1053, 1056),\n",
       "  (1056, 1057),\n",
       "  (1057, 1058),\n",
       "  (1058, 1059),\n",
       "  (1060, 1067),\n",
       "  (1068, 1076),\n",
       "  (1076, 1077),\n",
       "  (1078, 1084),\n",
       "  (1085, 1090),\n",
       "  (1090, 1091),\n",
       "  (1092, 1095),\n",
       "  (1096, 1102),\n",
       "  (1102, 1105),\n",
       "  (1105, 1106),\n",
       "  (1107, 1110),\n",
       "  (1111, 1118),\n",
       "  (1119, 1121),\n",
       "  (1121, 1124),\n",
       "  (1124, 1125),\n",
       "  (1125, 1126),\n",
       "  (1127, 1128),\n",
       "  (1128, 1134),\n",
       "  (1135, 1137),\n",
       "  (1138, 1146),\n",
       "  (1147, 1155),\n",
       "  (1155, 1156),\n",
       "  (1157, 1163),\n",
       "  (1164, 1168),\n",
       "  (1168, 1169),\n",
       "  (1170, 1175),\n",
       "  (1176, 1182),\n",
       "  (1182, 1183),\n",
       "  (1184, 1185),\n",
       "  (1185, 1188),\n",
       "  (1189, 1196),\n",
       "  (1197, 1198),\n",
       "  (1198, 1201),\n",
       "  (1201, 1204),\n",
       "  (1204, 1205),\n",
       "  (1206, 1211),\n",
       "  (1212, 1215),\n",
       "  (1215, 1218),\n",
       "  (1218, 1219),\n",
       "  (1220, 1228),\n",
       "  (1229, 1236),\n",
       "  (1237, 1240),\n",
       "  (1241, 1248),\n",
       "  (1248, 1249),\n",
       "  (1250, 1254),\n",
       "  (1255, 1265),\n",
       "  (1265, 1266),\n",
       "  (1267, 1270),\n",
       "  (1271, 1276),\n",
       "  (1277, 1279),\n",
       "  (1279, 1281),\n",
       "  (1281, 1284),\n",
       "  (1284, 1285),\n",
       "  (1286, 1296),\n",
       "  (1297, 1303),\n",
       "  (1304, 1309),\n",
       "  (1310, 1316),\n",
       "  (1316, 1317),\n",
       "  (1318, 1326),\n",
       "  (1327, 1334),\n",
       "  (1335, 1339),\n",
       "  (1340, 1343),\n",
       "  (1343, 1345),\n",
       "  (1345, 1346),\n",
       "  (1346, 1347),\n",
       "  (1348, 1351),\n",
       "  (1352, 1358),\n",
       "  (1359, 1363),\n",
       "  (1363, 1364),\n",
       "  (1365, 1371),\n",
       "  (1372, 1379),\n",
       "  (1380, 1385),\n",
       "  (1386, 1393),\n",
       "  (1394, 1397),\n",
       "  (1398, 1402),\n",
       "  (1403, 1410),\n",
       "  (1410, 1411),\n",
       "  (1412, 1418),\n",
       "  (1419, 1425),\n",
       "  (1426, 1431),\n",
       "  (1432, 1438),\n",
       "  (1438, 1439),\n",
       "  (1440, 1447),\n",
       "  (1448, 1451),\n",
       "  (1452, 1454),\n",
       "  (1454, 1457),\n",
       "  (1457, 1463),\n",
       "  (1463, 1464),\n",
       "  (1465, 1470),\n",
       "  (1471, 1475),\n",
       "  (1476, 1479),\n",
       "  (1480, 1485),\n",
       "  (1485, 1486),\n",
       "  (1487, 1493),\n",
       "  (1494, 1499),\n",
       "  (1500, 1507),\n",
       "  (1507, 1508),\n",
       "  (1509, 1518),\n",
       "  (1519, 1526),\n",
       "  (1527, 1531),\n",
       "  (1531, 1532),\n",
       "  (1533, 1540),\n",
       "  (1541, 1546),\n",
       "  (1547, 1550),\n",
       "  (1551, 1555),\n",
       "  (1556, 1562),\n",
       "  (1562, 1563),\n",
       "  (1564, 1569),\n",
       "  (1570, 1575),\n",
       "  (1576, 1583),\n",
       "  (1584, 1591),\n",
       "  (1592, 1596),\n",
       "  (1596, 1599),\n",
       "  (1599, 1600),\n",
       "  (1601, 1606),\n",
       "  (1607, 1619),\n",
       "  (1620, 1628),\n",
       "  (1629, 1631),\n",
       "  (1631, 1634),\n",
       "  (1634, 1635),\n",
       "  (1636, 1646),\n",
       "  (1647, 1649),\n",
       "  (1649, 1651),\n",
       "  (1652, 1654),\n",
       "  (1654, 1657),\n",
       "  (1657, 1660),\n",
       "  (0, 0)],\n",
       " [(0, 0),\n",
       "  (0, 4),\n",
       "  (5, 9),\n",
       "  (10, 18),\n",
       "  (19, 26),\n",
       "  (27, 35),\n",
       "  (36, 40),\n",
       "  (40, 41),\n",
       "  (0, 0),\n",
       "  (1057, 1058),\n",
       "  (1058, 1059),\n",
       "  (1060, 1067),\n",
       "  (1068, 1076),\n",
       "  (1076, 1077),\n",
       "  (1078, 1084),\n",
       "  (1085, 1090),\n",
       "  (1090, 1091),\n",
       "  (1092, 1095),\n",
       "  (1096, 1102),\n",
       "  (1102, 1105),\n",
       "  (1105, 1106),\n",
       "  (1107, 1110),\n",
       "  (1111, 1118),\n",
       "  (1119, 1121),\n",
       "  (1121, 1124),\n",
       "  (1124, 1125),\n",
       "  (1125, 1126),\n",
       "  (1127, 1128),\n",
       "  (1128, 1134),\n",
       "  (1135, 1137),\n",
       "  (1138, 1146),\n",
       "  (1147, 1155),\n",
       "  (1155, 1156),\n",
       "  (1157, 1163),\n",
       "  (1164, 1168),\n",
       "  (1168, 1169),\n",
       "  (1170, 1175),\n",
       "  (1176, 1182),\n",
       "  (1182, 1183),\n",
       "  (1184, 1185),\n",
       "  (1185, 1188),\n",
       "  (1189, 1196),\n",
       "  (1197, 1198),\n",
       "  (1198, 1201),\n",
       "  (1201, 1204),\n",
       "  (1204, 1205),\n",
       "  (1206, 1211),\n",
       "  (1212, 1215),\n",
       "  (1215, 1218),\n",
       "  (1218, 1219),\n",
       "  (1220, 1228),\n",
       "  (1229, 1236),\n",
       "  (1237, 1240),\n",
       "  (1241, 1248),\n",
       "  (1248, 1249),\n",
       "  (1250, 1254),\n",
       "  (1255, 1265),\n",
       "  (1265, 1266),\n",
       "  (1267, 1270),\n",
       "  (1271, 1276),\n",
       "  (1277, 1279),\n",
       "  (1279, 1281),\n",
       "  (1281, 1284),\n",
       "  (1284, 1285),\n",
       "  (1286, 1296),\n",
       "  (1297, 1303),\n",
       "  (1304, 1309),\n",
       "  (1310, 1316),\n",
       "  (1316, 1317),\n",
       "  (1318, 1326),\n",
       "  (1327, 1334),\n",
       "  (1335, 1339),\n",
       "  (1340, 1343),\n",
       "  (1343, 1345),\n",
       "  (1345, 1346),\n",
       "  (1346, 1347),\n",
       "  (1348, 1351),\n",
       "  (1352, 1358),\n",
       "  (1359, 1363),\n",
       "  (1363, 1364),\n",
       "  (1365, 1371),\n",
       "  (1372, 1379),\n",
       "  (1380, 1385),\n",
       "  (1386, 1393),\n",
       "  (1394, 1397),\n",
       "  (1398, 1402),\n",
       "  (1403, 1410),\n",
       "  (1410, 1411),\n",
       "  (1412, 1418),\n",
       "  (1419, 1425),\n",
       "  (1426, 1431),\n",
       "  (1432, 1438),\n",
       "  (1438, 1439),\n",
       "  (1440, 1447),\n",
       "  (1448, 1451),\n",
       "  (1452, 1454),\n",
       "  (1454, 1457),\n",
       "  (1457, 1463),\n",
       "  (1463, 1464),\n",
       "  (1465, 1470),\n",
       "  (1471, 1475),\n",
       "  (1476, 1479),\n",
       "  (1480, 1485),\n",
       "  (1485, 1486),\n",
       "  (1487, 1493),\n",
       "  (1494, 1499),\n",
       "  (1500, 1507),\n",
       "  (1507, 1508),\n",
       "  (1509, 1518),\n",
       "  (1519, 1526),\n",
       "  (1527, 1531),\n",
       "  (1531, 1532),\n",
       "  (1533, 1540),\n",
       "  (1541, 1546),\n",
       "  (1547, 1550),\n",
       "  (1551, 1555),\n",
       "  (1556, 1562),\n",
       "  (1562, 1563),\n",
       "  (1564, 1569),\n",
       "  (1570, 1575),\n",
       "  (1576, 1583),\n",
       "  (1584, 1591),\n",
       "  (1592, 1596),\n",
       "  (1596, 1599),\n",
       "  (1599, 1600),\n",
       "  (1601, 1606),\n",
       "  (1607, 1619),\n",
       "  (1620, 1628),\n",
       "  (1629, 1631),\n",
       "  (1631, 1634),\n",
       "  (1634, 1635),\n",
       "  (1636, 1646),\n",
       "  (1647, 1649),\n",
       "  (1649, 1651),\n",
       "  (1652, 1654),\n",
       "  (1654, 1657),\n",
       "  (1657, 1660),\n",
       "  (1661, 1664),\n",
       "  (1665, 1671),\n",
       "  (1672, 1678),\n",
       "  (1678, 1679),\n",
       "  (1680, 1688),\n",
       "  (1689, 1696),\n",
       "  (1697, 1702),\n",
       "  (1702, 1703),\n",
       "  (1704, 1708),\n",
       "  (1709, 1715),\n",
       "  (1716, 1720),\n",
       "  (1721, 1724),\n",
       "  (1724, 1727),\n",
       "  (1727, 1728),\n",
       "  (1729, 1739),\n",
       "  (1740, 1752),\n",
       "  (1753, 1757),\n",
       "  (1758, 1762),\n",
       "  (1762, 1764),\n",
       "  (1765, 1768),\n",
       "  (1769, 1777),\n",
       "  (1778, 1784),\n",
       "  (1784, 1785),\n",
       "  (1786, 1789),\n",
       "  (1790, 1794),\n",
       "  (1795, 1800),\n",
       "  (1801, 1811),\n",
       "  (1812, 1817),\n",
       "  (1818, 1826),\n",
       "  (1826, 1827),\n",
       "  (1828, 1831),\n",
       "  (1831, 1834),\n",
       "  (1834, 1835),\n",
       "  (1836, 1843),\n",
       "  (1844, 1845),\n",
       "  (1845, 1846),\n",
       "  (1847, 1854),\n",
       "  (1854, 1855),\n",
       "  (1856, 1858),\n",
       "  (1858, 1859),\n",
       "  (1859, 1860),\n",
       "  (1861, 1864),\n",
       "  (1865, 1869),\n",
       "  (1869, 1871),\n",
       "  (1872, 1874),\n",
       "  (1874, 1878),\n",
       "  (1878, 1879),\n",
       "  (1879, 1880),\n",
       "  (1881, 1891),\n",
       "  (1892, 1898),\n",
       "  (1899, 1906),\n",
       "  (1906, 1907),\n",
       "  (1908, 1910),\n",
       "  (1910, 1911),\n",
       "  (1911, 1913),\n",
       "  (1913, 1914),\n",
       "  (1915, 1917),\n",
       "  (1918, 1920),\n",
       "  (1920, 1921),\n",
       "  (1921, 1922),\n",
       "  (1923, 1926),\n",
       "  (1927, 1931),\n",
       "  (1932, 1933),\n",
       "  (1933, 1936),\n",
       "  (1936, 1939),\n",
       "  (1939, 1940),\n",
       "  (1941, 1943),\n",
       "  (1943, 1945),\n",
       "  (1945, 1947),\n",
       "  (1947, 1950),\n",
       "  (1951, 1959),\n",
       "  (1960, 1963),\n",
       "  (1964, 1969),\n",
       "  (1970, 1978),\n",
       "  (1979, 1981),\n",
       "  (1982, 1989),\n",
       "  (1989, 1990),\n",
       "  (1991, 1997),\n",
       "  (1998, 2006),\n",
       "  (2006, 2007),\n",
       "  (2008, 2013),\n",
       "  (2014, 2020),\n",
       "  (2021, 2028),\n",
       "  (2029, 2037),\n",
       "  (2038, 2045),\n",
       "  (2046, 2047),\n",
       "  (2047, 2048),\n",
       "  (2049, 2056),\n",
       "  (2056, 2057),\n",
       "  (2058, 2071),\n",
       "  (2072, 2075),\n",
       "  (2076, 2083),\n",
       "  (2084, 2090),\n",
       "  (2091, 2098),\n",
       "  (2099, 2104),\n",
       "  (2104, 2105),\n",
       "  (2106, 2109),\n",
       "  (2110, 2118),\n",
       "  (2118, 2120),\n",
       "  (2120, 2124),\n",
       "  (2124, 2125),\n",
       "  (2126, 2135),\n",
       "  (2136, 2140),\n",
       "  (2141, 2149),\n",
       "  (2150, 2152),\n",
       "  (2152, 2153),\n",
       "  (2153, 2160),\n",
       "  (2161, 2166),\n",
       "  (2167, 2171),\n",
       "  (2171, 2172),\n",
       "  (2173, 2179),\n",
       "  (2180, 2187),\n",
       "  (2188, 2195),\n",
       "  (2196, 2202),\n",
       "  (2203, 2210),\n",
       "  (2210, 2211),\n",
       "  (2212, 2218),\n",
       "  (2219, 2222),\n",
       "  (2223, 2228),\n",
       "  (2229, 2231),\n",
       "  (2231, 2234),\n",
       "  (2234, 2237),\n",
       "  (2237, 2238),\n",
       "  (2239, 2242),\n",
       "  (2242, 2244),\n",
       "  (2245, 2252),\n",
       "  (2253, 2262),\n",
       "  (2263, 2264),\n",
       "  (2264, 2265),\n",
       "  (2266, 2271),\n",
       "  (2271, 2272),\n",
       "  (2273, 2277),\n",
       "  (2278, 2284),\n",
       "  (2285, 2294),\n",
       "  (2295, 2302),\n",
       "  (2303, 2305),\n",
       "  (2305, 2307),\n",
       "  (2307, 2309),\n",
       "  (2309, 2310),\n",
       "  (2311, 2321),\n",
       "  (2322, 2326),\n",
       "  (2327, 2329),\n",
       "  (2329, 2330),\n",
       "  (2330, 2337),\n",
       "  (2338, 2342),\n",
       "  (2343, 2349),\n",
       "  (2349, 2350),\n",
       "  (2351, 2354),\n",
       "  (2355, 2363),\n",
       "  (2363, 2364),\n",
       "  (2364, 2378),\n",
       "  (2379, 2382),\n",
       "  (2383, 2387),\n",
       "  (2388, 2394),\n",
       "  (2394, 2397),\n",
       "  (2397, 2398),\n",
       "  (2399, 2406),\n",
       "  (2407, 2409),\n",
       "  (2410, 2420),\n",
       "  (2421, 2433),\n",
       "  (2434, 2440),\n",
       "  (2441, 2450),\n",
       "  (2451, 2454),\n",
       "  (2454, 2457),\n",
       "  (2457, 2458),\n",
       "  (0, 0),\n",
       "  (0, 0),\n",
       "  (0, 0),\n",
       "  (0, 0),\n",
       "  (0, 0),\n",
       "  (0, 0),\n",
       "  (0, 0),\n",
       "  (0, 0),\n",
       "  (0, 0),\n",
       "  (0, 0),\n",
       "  (0, 0),\n",
       "  (0, 0),\n",
       "  (0, 0),\n",
       "  (0, 0),\n",
       "  (0, 0),\n",
       "  (0, 0),\n",
       "  (0, 0),\n",
       "  (0, 0),\n",
       "  (0, 0),\n",
       "  (0, 0),\n",
       "  (0, 0),\n",
       "  (0, 0),\n",
       "  (0, 0),\n",
       "  (0, 0),\n",
       "  (0, 0),\n",
       "  (0, 0),\n",
       "  (0, 0),\n",
       "  (0, 0),\n",
       "  (0, 0),\n",
       "  (0, 0),\n",
       "  (0, 0),\n",
       "  (0, 0),\n",
       "  (0, 0),\n",
       "  (0, 0),\n",
       "  (0, 0),\n",
       "  (0, 0),\n",
       "  (0, 0),\n",
       "  (0, 0),\n",
       "  (0, 0),\n",
       "  (0, 0),\n",
       "  (0, 0),\n",
       "  (0, 0),\n",
       "  (0, 0),\n",
       "  (0, 0),\n",
       "  (0, 0),\n",
       "  (0, 0),\n",
       "  (0, 0),\n",
       "  (0, 0),\n",
       "  (0, 0),\n",
       "  (0, 0),\n",
       "  (0, 0),\n",
       "  (0, 0),\n",
       "  (0, 0),\n",
       "  (0, 0),\n",
       "  (0, 0),\n",
       "  (0, 0),\n",
       "  (0, 0),\n",
       "  (0, 0),\n",
       "  (0, 0),\n",
       "  (0, 0),\n",
       "  (0, 0),\n",
       "  (0, 0),\n",
       "  (0, 0),\n",
       "  (0, 0),\n",
       "  (0, 0),\n",
       "  (0, 0),\n",
       "  (0, 0),\n",
       "  (0, 0),\n",
       "  (0, 0),\n",
       "  (0, 0),\n",
       "  (0, 0),\n",
       "  (0, 0),\n",
       "  (0, 0),\n",
       "  (0, 0),\n",
       "  (0, 0),\n",
       "  (0, 0),\n",
       "  (0, 0),\n",
       "  (0, 0),\n",
       "  (0, 0),\n",
       "  (0, 0),\n",
       "  (0, 0),\n",
       "  (0, 0)]]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offset_mapping = tokenised_examples.pop(\"offset_mapping\")\n",
    "offset_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134b50e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "847b2116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0, 45093,  2788,     7,  1296,   480, 19233,  6315,   646,  1001,\n",
      "          6747,   102,    12, 11070,   742,     2]])\n"
     ]
    }
   ],
   "source": [
    "# test the tokeniser\n",
    "test_input = \"Simple text to test -- tokenizer [roberta-base]\"\n",
    "tokenised_test_input = tokeniser.encode(test_input, return_tensors=\"pt\")\n",
    "print(tokenised_test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "92e7e328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s>', 'Simple', 'Ġtext', 'Ġto', 'Ġtest', 'Ġ--', 'Ġtoken', 'izer', 'Ġ[', 'ro', 'bert', 'a', '-', 'base', ']', '</s>']\n"
     ]
    }
   ],
   "source": [
    "test_token_id_to_text = tokeniser.convert_ids_to_tokens(tokeniser.encode(test_input))\n",
    "print(test_token_id_to_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cb65310c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the model\n",
    "test_output = model(tokenised_test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9e6b4cac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 16, 768]), torch.Size([1, 768]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "First output:\n",
    "# (1,16,768): batch_size * #tokens * embedding_size_defined_by_model\n",
    "# our input is one sentence with 16 tokens\n",
    "Second output - pooler output, the embedding result of the first token of the sequence <s>\n",
    "\"\"\"\n",
    "test_output[0].size(), test_output[1].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "873e3e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def manual_prompt(questions, answers, template):\n",
    "    prompt = questions + template + answers\n",
    "    prompt_token_id = tokeniser(prompt, return_tensors=\"pt\").input_ids\n",
    "    prompt_id_to_text = tokeniser.convert_ids_to_tokens(prompt_token_id[0])\n",
    "    mask_token_pos = prompt_id_to_text.index(tokeniser.mask_token)\n",
    "    return prompt_token_id, mask_token_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cdb15512",
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_template = \" <mask>. \"\n",
    "prompt_token_id, mask_token_pos = manual_prompt(qnli_train[0]['text1'], qnli_train[0]['text2'], manual_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a1941df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 62, 768])\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = model(prompt_token_id)[0]\n",
    "print(predictions.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a096df1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "values, indices = torch.sort(predictions[0, mask_token_pos], descending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dce1cb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = list(zip(tokeniser.convert_ids_to_tokens(indices), values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e2d52a99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Ġreal', tensor(10.4360))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e7750573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qnli_train[0]['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a8287e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check whether dataset is balanced\n",
    "def is_balanced(dataset, threshold=0.1):\n",
    "    all_labels = torch.tensor(dataset)\n",
    "    ratio = all_labels.sum() / len(all_labels)\n",
    "    return abs(2 * ratio - 1) < 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e91d7bbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(True), tensor(False), tensor(True))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_balanced(qnli_train['label']), is_balanced(qnli_test['label']), is_balanced(qnli_val['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "db4be693",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 'not entailment')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qnli_train[0]['label'], qnli_train[0]['label_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5bd88a51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(270, 2458)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the max length of question and answer\n",
    "max([len(i) for i in qnli_train['text1']]), max([len(i) for i in qnli_train['text2']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1f0f2b84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2711)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(torch.tensor([len(i) for i in qnli_train['text2']]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88882c4",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "25366573",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "PARAMS = {\n",
    "    \"batch_size\": 24,\n",
    "    \"lr\": 1e-3,\n",
    "    \"max_epochs\": 1,\n",
    "    \"model_name\": \"distilbert-base-uncased\",\n",
    "    \"max_length\": 384, \n",
    "    \"doc_stride\": 128, # because text2 is too long, bert can only accept 512 tokens\n",
    "    \"random_seed\": 42\n",
    "}\n",
    "pl.seed_everything(PARAMS['random_seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2dab00f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class QNLIDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.data.iloc[index]\n",
    "        question = row.text1\n",
    "        answer = row.text2\n",
    "        label = row.label\n",
    "        label_text = row.label_text\n",
    "        \n",
    "        tok_input = self.tokenizer(\n",
    "            question,\n",
    "            answer,\n",
    "            truncation = \"only_second\",\n",
    "            max_length = PARAMS[\"max_length\"],\n",
    "            stride = PARAMS[\"doc_stride\"],\n",
    "            return_overflowing_tokens=True,\n",
    "            return_offsets_mapping=True,\n",
    "            padding=\"max_length\"\n",
    "        )\n",
    "        \n",
    "        sample_mapping = tok_input\n",
    "        \n",
    "        return dict(\n",
    "            prompt=prompt,\n",
    "            input_ids=end_prompt[\"input_ids\"].flatten(),\n",
    "            attention_mask=end_prompt[\"attention_mask\"].flatten(),\n",
    "            label=torch.FloatTensor(label),\n",
    "            label_text=label_text\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "57755a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "class QNLIDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, train_data, val_data, test_data, tokenizer, template, batch_size, max_token_len):\n",
    "        super().__init__()\n",
    "        self.train_data = train_data\n",
    "        self.val_data = val_data\n",
    "        self.test_data = test_data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.batch_size = batch_size\n",
    "        self.max_token_len = max_token_len\n",
    "        \n",
    "    def setup(self):\n",
    "        self.train_dataset = QNLIDataset(\n",
    "            self.train_data,\n",
    "            self.tokenizer,\n",
    "            self.max_token_len,\n",
    "            self.template\n",
    "        )\n",
    "        \n",
    "        self.val_dataset = QNLIDataset(\n",
    "            self.val_data,\n",
    "            self.tokenizer,\n",
    "            self.max_token_len,\n",
    "            self.template\n",
    "        )\n",
    "        \n",
    "        self.test_dataset = QNLIDataset(\n",
    "            self.test_data,\n",
    "            self.tokenizer,\n",
    "            self.max_token_len,\n",
    "            self.template\n",
    "        )\n",
    "        \n",
    "    def train_dataloader(self):\n",
    "        return Dataloader(\n",
    "            self.train_dataset,\n",
    "            batch_size = self.batch_size,\n",
    "            shuffle = True,\n",
    "            num_workers = 2\n",
    "        )\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return Dataloader(\n",
    "            self.val_dataset,\n",
    "            batch_size = self.batch_size,\n",
    "            shuffle = True,\n",
    "            num_workers = 2\n",
    "        )\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return Dataloader(\n",
    "            self.test_dataset,\n",
    "            batch_size = self.batch_size,\n",
    "            shuffle = True,\n",
    "            num_workers = 2\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e8ead402",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "class QNLIClassifier(pl.LightningModule):\n",
    "    def __init__(self, n_classes: int, n_training_steps=None, n_warmup_steps=None):\n",
    "        super().__init__()\n",
    "        self.bert = AutoModel.from_pretrained(PARAMS['model_name'], return_dict=True)\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
    "        self.n_training_steps = n_training_steps\n",
    "        self.n_warmup_steps = n_warmup_steps\n",
    "        self.criterion = nn.BCELoss()\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        output = self.bert(input_ids, attention_mask=attention_mask)\n",
    "        output = self.classifier(output.pooler_output)\n",
    "        output = torch.sigmoid(output)\n",
    "        loss = 0\n",
    "        if labels is not None:\n",
    "            loss = self.criterion(output, labels)\n",
    "        return loss, output\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        labels = batch[\"labels\"]\n",
    "        loss, outputs = self(input_ids, attention_mask, labels)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True, logger=True)\n",
    "        return {\"loss\": loss, \"predictions\": outputs, \"labels\": labels}\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        labels = batch[\"labels\"]\n",
    "        loss, outputs = self(input_ids, attention_mask, labels)\n",
    "        self.log(\"val_loss\", loss, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        labels = batch[\"labels\"]\n",
    "        loss, outputs = self(input_ids, attention_mask, labels)\n",
    "        self.log(\"test_loss\", loss, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def training_epoch_end(self, outputs):\n",
    "        labels = []\n",
    "        predictions = []\n",
    "        for output in outputs:\n",
    "            for out_labels in output[\"labels\"].detach().cpu():\n",
    "                labels.append(out_labels)\n",
    "            for out_predictions in output[\"predictions\"].detach().cpu():\n",
    "                predictions.append(out_predictions)\n",
    "        \n",
    "        labels = torch.stack(labels).int()\n",
    "        predictions = torch.stack(predictions)\n",
    "        \n",
    "        class_roc_auc = auroc(predictions[:, 0], labels[:, 0])\n",
    "        self.logger.experiment.add_scalar(f\"{label}_roc_auc/Train\", class_roc_auc, self.current_epoch)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = AdamW(self.parameters(), lr=PARAMS['lr'])\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            optimizer,\n",
    "            num_warmup_steps=self.n_warmup_steps,\n",
    "            num_training_steps=self.n_training_steps\n",
    "        ) # learning rate scheduler\n",
    "        \n",
    "        return dict(\n",
    "            optimizer=optimizer,\n",
    "            lr_scheduler=dict(\n",
    "                scheduler=scheduler,\n",
    "                interval='step'\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "89a03199",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import torch.nn as nn\n",
    "def prepare_and_train(train_df, val_df, test_df, template):\n",
    "    \"\"\" Training best practices\n",
    "        - Checkpointing that saves the best model based on validation loss\n",
    "        - Logging the progress in TensorBoard\n",
    "        - Early stopping that terminates the training when the loss has not improved for the last 2 epochs\n",
    "    \"\"\"\n",
    "    logger = TensorBoardLogger('/local/scratch-3/yz709/nlp-prompt-attack/tb_logs', name='discrete-prompt-roberta-base')\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        dirpath='checkpoints',\n",
    "        filename='discrete-prompt-roberta-base-{epoch:02d}-{val_loss:.2f}',\n",
    "        verbose=True,\n",
    "        monitor='val_loss',\n",
    "        mode='min'\n",
    "    )\n",
    "    early_stopping_callback = EarlyStopping(monitor='val_loss', patience=2)\n",
    "    \n",
    "    # preprocess data\n",
    "    tokenizer = AutoTokenizer.from_pretrained(PARAMS['model_name'])\n",
    "    train_dataset = QNLIDataset(train_df, tokenizer, PARAMS['max_token_count'], template)\n",
    "    data_module = QNLIDataModule(\n",
    "        train_df,\n",
    "        val_df,\n",
    "        test_df,\n",
    "        tokenizer,\n",
    "        template,\n",
    "        batch_size=PARAMS['batch_size'],\n",
    "        max_token_len=PARAMS['max_token_count']\n",
    "    )\n",
    "\n",
    "    # model\n",
    "    steps_per_epoch = len(train_df) // PARAMS['batch_size']\n",
    "    total_training_steps = steps_per_epoch * PARAMS['max_epochs']\n",
    "    warmup_steps = total_training_steps // 5\n",
    "    model = QNLIClassifier(\n",
    "        n_classes=2,\n",
    "        n_warmup_steps=warmup_steps,\n",
    "        n_training_steps=total_training_steps\n",
    "    )\n",
    "    \n",
    "    # train\n",
    "    trainer = pl.Trainer(\n",
    "        logger = logger,\n",
    "        callbacks=[early_stopping_callback,checkpoint_callback],\n",
    "        max_epochs=PARAMS['max_epochs'],\n",
    "        accelerator=\"gpu\", \n",
    "        devices=[1],\n",
    "    )\n",
    "    trainer.fit(model, data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f5651f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "ename": "MisconfigurationException",
     "evalue": "`QNLIDataModule.setup` does not have a `stage` argument.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMisconfigurationException\u001b[0m                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [44]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mprepare_and_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqnli_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqnli_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqnli_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemplate\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m <mask> \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [43]\u001b[0m, in \u001b[0;36mprepare_and_train\u001b[0;34m(train_df, val_df, test_df, template)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# train\u001b[39;00m\n\u001b[1;32m     44\u001b[0m trainer \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mTrainer(\n\u001b[1;32m     45\u001b[0m     logger \u001b[38;5;241m=\u001b[39m logger,\n\u001b[1;32m     46\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[early_stopping_callback,checkpoint_callback],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     49\u001b[0m     devices\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m     50\u001b[0m )\n\u001b[0;32m---> 51\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_module\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/local/scratch-3/yz709/anaconda3/envs/nlp-prompt-attack-env/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:696\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    678\u001b[0m \u001b[38;5;124;03mRuns the full optimization routine.\u001b[39;00m\n\u001b[1;32m    679\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    693\u001b[0m \u001b[38;5;124;03m    datamodule: An instance of :class:`~pytorch_lightning.core.datamodule.LightningDataModule`.\u001b[39;00m\n\u001b[1;32m    694\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    695\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m model\n\u001b[0;32m--> 696\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/local/scratch-3/yz709/anaconda3/envs/nlp-prompt-attack-env/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:650\u001b[0m, in \u001b[0;36mTrainer._call_and_handle_interrupt\u001b[0;34m(self, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    648\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    649\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 650\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    651\u001b[0m \u001b[38;5;66;03m# TODO(awaelchli): Unify both exceptions below, where `KeyboardError` doesn't re-raise\u001b[39;00m\n\u001b[1;32m    652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n",
      "File \u001b[0;32m/local/scratch-3/yz709/anaconda3/envs/nlp-prompt-attack-env/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:735\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    731\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m ckpt_path \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresume_from_checkpoint\n\u001b[1;32m    732\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__set_ckpt_path(\n\u001b[1;32m    733\u001b[0m     ckpt_path, model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    734\u001b[0m )\n\u001b[0;32m--> 735\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    737\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[1;32m    738\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/local/scratch-3/yz709/anaconda3/envs/nlp-prompt-attack-env/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1091\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   1088\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callback_connector\u001b[38;5;241m.\u001b[39m_attach_model_callbacks()\n\u001b[1;32m   1089\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callback_connector\u001b[38;5;241m.\u001b[39m_attach_model_logging_functions()\n\u001b[0;32m-> 1091\u001b[0m \u001b[43mverify_loop_configurations\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1093\u001b[0m \u001b[38;5;66;03m# hook\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m log\u001b[38;5;241m.\u001b[39mdetail(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: preparing data\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/local/scratch-3/yz709/anaconda3/envs/nlp-prompt-attack-env/lib/python3.10/site-packages/pytorch_lightning/trainer/configuration_validator.py:60\u001b[0m, in \u001b[0;36mverify_loop_configurations\u001b[0;34m(trainer)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# TODO: Delete CheckpointHooks off LightningDataModule in v1.8\u001b[39;00m\n\u001b[1;32m     59\u001b[0m _check_datamodule_checkpoint_hooks(trainer)\n\u001b[0;32m---> 60\u001b[0m \u001b[43m_check_setup_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/local/scratch-3/yz709/anaconda3/envs/nlp-prompt-attack-env/lib/python3.10/site-packages/pytorch_lightning/trainer/configuration_validator.py:308\u001b[0m, in \u001b[0;36m_check_setup_method\u001b[0;34m(trainer)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m [trainer\u001b[38;5;241m.\u001b[39mlightning_module, trainer\u001b[38;5;241m.\u001b[39mdatamodule] \u001b[38;5;241m+\u001b[39m trainer\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[1;32m    307\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_overridden(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msetup\u001b[39m\u001b[38;5;124m\"\u001b[39m, obj) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_param_in_hook_signature(obj\u001b[38;5;241m.\u001b[39msetup, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstage\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 308\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m MisconfigurationException(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.setup` does not have a `stage` argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mMisconfigurationException\u001b[0m: `QNLIDataModule.setup` does not have a `stage` argument."
     ]
    }
   ],
   "source": [
    "prepare_and_train(qnli_train, qnli_val, qnli_test, template = \" <mask> \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c72723",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95dec6bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b97383",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
