{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "019dcbd0",
   "metadata": {},
   "source": [
    "# Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3758580",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73980eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "411c59f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer, AdamW, AutoConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0ecc82",
   "metadata": {},
   "source": [
    "# Download datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e3dc71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnli_path = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "165f66cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Found cached dataset multi_nli (/home/yz709/.cache/huggingface/datasets/multi_nli/default/0.0.0/591f72eb6263d1ab527561777936b199b714cda156d35716881158a2bd144f39)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2a79080316a49e88b51b66216812254",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if mnli_path == None:\n",
    "    mnli = load_dataset(\"multi_nli\")\n",
    "    mnli_path = \"./datasets/mnli\"\n",
    "    mnli.save_to_disk(mnli_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3663e374",
   "metadata": {},
   "outputs": [],
   "source": [
    "qnli_path = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7915d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration SetFit--qnli-324fd6914ad1beff\n",
      "Found cached dataset json (/home/yz709/.cache/huggingface/datasets/SetFit___json/SetFit--qnli-324fd6914ad1beff/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07512ae5a5604d4a8ca75874d36f54d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if qnli_path == None:\n",
    "    qnli = load_dataset(\"SetFit/qnli\")\n",
    "    qnli_path = \"./datasets/qnli\"\n",
    "    qnli.save_to_disk(qnli_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe49be5",
   "metadata": {},
   "source": [
    "# Inspect datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b43448",
   "metadata": {},
   "source": [
    "## For qnli dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e00543fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text1', 'text2', 'label', 'idx', 'label_text'],\n",
       "        num_rows: 104743\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text1', 'text2', 'label', 'idx', 'label_text'],\n",
       "        num_rows: 5463\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text1', 'text2', 'label', 'idx', 'label_text'],\n",
       "        num_rows: 5463\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qnli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b79a1f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "qnli_train = qnli['train']\n",
    "qnli_test = qnli['test']\n",
    "qnli_val = qnli['validation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41480f7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text1': ['What individual was responsible for law and maintaining order in the county?',\n",
       "  'How much of the gross domestic product was spent on public health in 2004?'],\n",
       " 'text2': ['He was the top civil and military leader of the commandery and handled defense, lawsuits, seasonal instructions to farmers and recommendations of nominees for office sent annually to the capital in a quota system first established by Emperor Wu.',\n",
       "  'Public expenditure health was at 8.9% of the GDP in 2004, whereas private expenditure was at 1.3%.'],\n",
       " 'label': [1, 0],\n",
       " 'idx': [104741, 104742],\n",
       " 'label_text': ['not entailment', 'entailment']}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# label 0 - entailment, label 1 - not entailment\n",
    "qnli_train[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5abbe76c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What individual was responsible for law and maintaining order in the county?',\n",
       " 'How much of the gross domestic product was spent on public health in 2004?']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qnli_train['text1'][-2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcea50ed",
   "metadata": {},
   "source": [
    "## For mnli dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72e1d1e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['promptID', 'pairID', 'premise', 'premise_binary_parse', 'premise_parse', 'hypothesis', 'hypothesis_binary_parse', 'hypothesis_parse', 'genre', 'label'],\n",
       "        num_rows: 392702\n",
       "    })\n",
       "    validation_matched: Dataset({\n",
       "        features: ['promptID', 'pairID', 'premise', 'premise_binary_parse', 'premise_parse', 'hypothesis', 'hypothesis_binary_parse', 'hypothesis_parse', 'genre', 'label'],\n",
       "        num_rows: 9815\n",
       "    })\n",
       "    validation_mismatched: Dataset({\n",
       "        features: ['promptID', 'pairID', 'premise', 'premise_binary_parse', 'premise_parse', 'hypothesis', 'hypothesis_binary_parse', 'hypothesis_parse', 'genre', 'label'],\n",
       "        num_rows: 9832\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "260f7ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnli_train = mnli['train']\n",
    "mnli_val_match = mnli['validation_matched']\n",
    "mnli_val_mismatch = mnli['validation_mismatched']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "341ca12a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['promptID', 'pairID', 'premise', 'premise_binary_parse', 'premise_parse', 'hypothesis', 'hypothesis_binary_parse', 'hypothesis_parse', 'genre', 'label'],\n",
       "    num_rows: 392702\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnli_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b7d8c18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'promptID': 31193,\n",
       " 'pairID': '31193n',\n",
       " 'premise': 'Conceptually cream skimming has two basic dimensions - product and geography.',\n",
       " 'premise_binary_parse': '( ( Conceptually ( cream skimming ) ) ( ( has ( ( ( two ( basic dimensions ) ) - ) ( ( product and ) geography ) ) ) . ) )',\n",
       " 'premise_parse': '(ROOT (S (NP (JJ Conceptually) (NN cream) (NN skimming)) (VP (VBZ has) (NP (NP (CD two) (JJ basic) (NNS dimensions)) (: -) (NP (NN product) (CC and) (NN geography)))) (. .)))',\n",
       " 'hypothesis': 'Product and geography are what make cream skimming work. ',\n",
       " 'hypothesis_binary_parse': '( ( ( Product and ) geography ) ( ( are ( what ( make ( cream ( skimming work ) ) ) ) ) . ) )',\n",
       " 'hypothesis_parse': '(ROOT (S (NP (NN Product) (CC and) (NN geography)) (VP (VBP are) (SBAR (WHNP (WP what)) (S (VP (VBP make) (NP (NP (NN cream)) (VP (VBG skimming) (NP (NN work)))))))) (. .)))',\n",
       " 'genre': 'government',\n",
       " 'label': 1}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnli_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "97c2a49b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'promptID': 37397,\n",
       " 'pairID': '37397e',\n",
       " 'premise': 'How do you know? All this is their information again.',\n",
       " 'premise_binary_parse': '( ( How ( ( ( do you ) know ) ? ) ) ( ( All this ) ( ( ( is ( their information ) ) again ) . ) ) )',\n",
       " 'premise_parse': '(ROOT (S (SBARQ (WHADVP (WRB How)) (SQ (VBP do) (NP (PRP you)) (VP (VB know))) (. ?)) (NP (PDT All) (DT this)) (VP (VBZ is) (NP (PRP$ their) (NN information)) (ADVP (RB again))) (. .)))',\n",
       " 'hypothesis': 'This information belongs to them.',\n",
       " 'hypothesis_binary_parse': '( ( This information ) ( ( belongs ( to them ) ) . ) )',\n",
       " 'hypothesis_parse': '(ROOT (S (NP (DT This) (NN information)) (VP (VBZ belongs) (PP (TO to) (NP (PRP them)))) (. .)))',\n",
       " 'genre': 'fiction',\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnli_train[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6412521",
   "metadata": {},
   "source": [
    "# Preprocess dataset QNLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d3f03942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# roberta-base or roberta-large\n",
    "PLM = \"roberta-base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "99464e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "model = AutoModel.from_pretrained(PLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f547cc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load tokeniser for the specific model\n",
    "tokeniser = AutoTokenizer.from_pretrained(PLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "847b2116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0, 45093,  2788,     7,  1296,   480, 19233,  6315,   646,  1001,\n",
      "          6747,   102,    12, 11070,   742,     2]])\n"
     ]
    }
   ],
   "source": [
    "# test the tokeniser\n",
    "test_input = \"Simple text to test -- tokenizer [roberta-base]\"\n",
    "tokenised_test_input = tokeniser.encode(test_input, return_tensors=\"pt\")\n",
    "print(tokenised_test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "92e7e328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s>', 'Simple', 'Ġtext', 'Ġto', 'Ġtest', 'Ġ--', 'Ġtoken', 'izer', 'Ġ[', 'ro', 'bert', 'a', '-', 'base', ']', '</s>']\n"
     ]
    }
   ],
   "source": [
    "test_token_id_to_text = tokeniser.convert_ids_to_tokens(tokeniser.encode(test_input))\n",
    "print(test_token_id_to_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cb65310c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the model\n",
    "test_output = model(tokenised_test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9e6b4cac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 16, 768]), torch.Size([1, 768]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "First output:\n",
    "# (1,16,768): batch_size * #tokens * embedding_size_defined_by_model\n",
    "# our input is one sentence with 16 tokens\n",
    "Second output - pooler output, the embedding result of the first token of the sequence <s>\n",
    "\"\"\"\n",
    "test_output[0].size(), test_output[1].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "873e3e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def manual_prompt(questions, answers, template):\n",
    "    prompt = questions + template + answers\n",
    "    prompt_token_id = tokeniser(prompt, return_tensors=\"pt\").input_ids\n",
    "    prompt_id_to_text = tokeniser.convert_ids_to_tokens(prompt_token_id[0])\n",
    "    mask_token_pos = prompt_id_to_text.index(tokeniser.mask_token)\n",
    "    return prompt_token_id, mask_token_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cdb15512",
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_template = \" <mask>. \"\n",
    "prompt_token_id, mask_token_pos = manual_prompt(qnli_train[0]['text1'], qnli_train[0]['text2'], manual_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a1941df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 62, 768])\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = model(prompt_token_id)[0]\n",
    "print(predictions.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a096df1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "values, indices = torch.sort(predictions[0, mask_token_pos], descending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dce1cb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = list(zip(tokeniser.convert_ids_to_tokens(indices), values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e2d52a99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Ġreal', tensor(10.4360))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e7750573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qnli_train[0]['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a8287e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check whether dataset is balanced\n",
    "def is_balanced(dataset, threshold=0.1):\n",
    "    all_labels = torch.tensor(dataset)\n",
    "    ratio = all_labels.sum() / len(all_labels)\n",
    "    return abs(2 * ratio - 1) < 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e91d7bbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(True), tensor(False), tensor(True))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_balanced(qnli_train['label']), is_balanced(qnli_test['label']), is_balanced(qnli_val['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "db4be693",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 'not entailment')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qnli_train[0]['label'], qnli_train[0]['label_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5bd88a51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(270, 2458)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the max length of question and answer\n",
    "max([len(i) for i in qnli_train['text1']]), max([len(i) for i in qnli_train['text2']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88882c4",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "25366573",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "PARAMS = {\n",
    "    \"batch_size\": 24,\n",
    "    \"lr\": 1e-3,\n",
    "    \"max_epochs\": 1,\n",
    "    \"model_name\": \"roberta-base\",\n",
    "    \"max_token_count\": 2048,\n",
    "    \"random_seed\": 42\n",
    "}\n",
    "pl.seed_everything(PARAMS['random_seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2dab00f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class QNLIDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_token_len, template):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = data\n",
    "        self.max_token_len = max_token_len\n",
    "        self.template = template\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.data.iloc[index]\n",
    "        question = row.text1\n",
    "        answer = row.text2\n",
    "        label = row.label\n",
    "        label_text = row.label_text\n",
    "        \n",
    "        # prompt = <question><SEP><template><answer><SEP> \n",
    "        prompt = question + \" \" + template + \", \" + answer\n",
    "        end_prompt = self.tokenizer.encode_plus(\n",
    "            prompt,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_token_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        \n",
    "        return dict(\n",
    "            prompt=prompt,\n",
    "            input_ids=end_prompt[\"input_ids\"].flatten(),\n",
    "            attention_mask=end_prompt[\"attention_mask\"].flatten(),\n",
    "            label=torch.FloatTensor(label),\n",
    "            label_text=label_text\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "57755a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "class QNLIDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, train_data, val_data, test_data, tokenizer, template, batch_size, max_token_len):\n",
    "        super().__init__()\n",
    "        self.train_data = train_data\n",
    "        self.val_data = val_data\n",
    "        self.test_data = test_data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.batch_size = batch_size\n",
    "        self.max_token_len = max_token_len\n",
    "        \n",
    "    def setup(self):\n",
    "        self.train_dataset = QNLIDataset(\n",
    "            self.train_data,\n",
    "            self.tokenizer,\n",
    "            self.max_token_len,\n",
    "            self.template\n",
    "        )\n",
    "        \n",
    "        self.val_dataset = QNLIDataset(\n",
    "            self.val_data,\n",
    "            self.tokenizer,\n",
    "            self.max_token_len,\n",
    "            self.template\n",
    "        )\n",
    "        \n",
    "        self.test_dataset = QNLIDataset(\n",
    "            self.test_data,\n",
    "            self.tokenizer,\n",
    "            self.max_token_len,\n",
    "            self.template\n",
    "        )\n",
    "        \n",
    "    def train_dataloader(self):\n",
    "        return Dataloader(\n",
    "            self.train_dataset,\n",
    "            batch_size = self.batch_size,\n",
    "            shuffle = True,\n",
    "            num_workers = 2\n",
    "        )\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return Dataloader(\n",
    "            self.val_dataset,\n",
    "            batch_size = self.batch_size,\n",
    "            shuffle = True,\n",
    "            num_workers = 2\n",
    "        )\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return Dataloader(\n",
    "            self.test_dataset,\n",
    "            batch_size = self.batch_size,\n",
    "            shuffle = True,\n",
    "            num_workers = 2\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e8ead402",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "class QNLIClassifier(pl.LightningModule):\n",
    "    def __init__(self, n_classes: int, n_training_steps=None, n_warmup_steps=None):\n",
    "        super().__init__()\n",
    "        self.bert = AutoModel.from_pretrained(PARAMS['model_name'], return_dict=True)\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
    "        self.n_training_steps = n_training_steps\n",
    "        self.n_warmup_steps = n_warmup_steps\n",
    "        self.criterion = nn.BCELoss()\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        output = self.bert(input_ids, attention_mask=attention_mask)\n",
    "        output = self.classifier(output.pooler_output)\n",
    "        output = torch.sigmoid(output)\n",
    "        loss = 0\n",
    "        if labels is not None:\n",
    "            loss = self.criterion(output, labels)\n",
    "        return loss, output\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        labels = batch[\"labels\"]\n",
    "        loss, outputs = self(input_ids, attention_mask, labels)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True, logger=True)\n",
    "        return {\"loss\": loss, \"predictions\": outputs, \"labels\": labels}\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        labels = batch[\"labels\"]\n",
    "        loss, outputs = self(input_ids, attention_mask, labels)\n",
    "        self.log(\"val_loss\", loss, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        labels = batch[\"labels\"]\n",
    "        loss, outputs = self(input_ids, attention_mask, labels)\n",
    "        self.log(\"test_loss\", loss, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def training_epoch_end(self, outputs):\n",
    "        labels = []\n",
    "        predictions = []\n",
    "        for output in outputs:\n",
    "            for out_labels in output[\"labels\"].detach().cpu():\n",
    "                labels.append(out_labels)\n",
    "            for out_predictions in output[\"predictions\"].detach().cpu():\n",
    "                predictions.append(out_predictions)\n",
    "        \n",
    "        labels = torch.stack(labels).int()\n",
    "        predictions = torch.stack(predictions)\n",
    "        \n",
    "        class_roc_auc = auroc(predictions[:, 0], labels[:, 0])\n",
    "        self.logger.experiment.add_scalar(f\"{label}_roc_auc/Train\", class_roc_auc, self.current_epoch)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = AdamW(self.parameters(), lr=PARAMS['lr'])\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            optimizer,\n",
    "            num_warmup_steps=self.n_warmup_steps,\n",
    "            num_training_steps=self.n_training_steps\n",
    "        ) # learning rate scheduler\n",
    "        \n",
    "        return dict(\n",
    "            optimizer=optimizer,\n",
    "            lr_scheduler=dict(\n",
    "                scheduler=scheduler,\n",
    "                interval='step'\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "89a03199",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import torch.nn as nn\n",
    "def prepare_and_train(train_df, val_df, test_df, template):\n",
    "    \"\"\" Training best practices\n",
    "        - Checkpointing that saves the best model based on validation loss\n",
    "        - Logging the progress in TensorBoard\n",
    "        - Early stopping that terminates the training when the loss has not improved for the last 2 epochs\n",
    "    \"\"\"\n",
    "    logger = TensorBoardLogger('/local/scratch-3/yz709/nlp-prompt-attack/tb_logs', name='discrete-prompt-roberta-base')\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        dirpath='checkpoints',\n",
    "        filename='discrete-prompt-roberta-base-{epoch:02d}-{val_loss:.2f}',\n",
    "        verbose=True,\n",
    "        monitor='val_loss',\n",
    "        mode='min'\n",
    "    )\n",
    "    early_stopping_callback = EarlyStopping(monitor='val_loss', patience=2)\n",
    "    \n",
    "    # preprocess data\n",
    "    tokenizer = AutoTokenizer.from_pretrained(PARAMS['model_name'])\n",
    "    train_dataset = QNLIDataset(train_df, tokenizer, PARAMS['max_token_count'], template)\n",
    "    data_module = QNLIDataModule(\n",
    "        train_df,\n",
    "        val_df,\n",
    "        test_df,\n",
    "        tokenizer,\n",
    "        template,\n",
    "        batch_size=PARAMS['batch_size'],\n",
    "        max_token_len=PARAMS['max_token_count']\n",
    "    )\n",
    "\n",
    "    # model\n",
    "    steps_per_epoch = len(train_df) // PARAMS['batch_size']\n",
    "    total_training_steps = steps_per_epoch * PARAMS['max_epochs']\n",
    "    warmup_steps = total_training_steps // 5\n",
    "    model = QNLIClassifier(\n",
    "        n_classes=2,\n",
    "        n_warmup_steps=warmup_steps,\n",
    "        n_training_steps=total_training_steps\n",
    "    )\n",
    "    \n",
    "    # train\n",
    "    trainer = pl.Trainer(\n",
    "        logger = logger,\n",
    "        callbacks=[early_stopping_callback,checkpoint_callback],\n",
    "        max_epochs=PARAMS['max_epochs'],\n",
    "        accelerator=\"gpu\", \n",
    "        devices=[1],\n",
    "    )\n",
    "    trainer.fit(model, data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f5651f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "ename": "MisconfigurationException",
     "evalue": "`QNLIDataModule.setup` does not have a `stage` argument.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMisconfigurationException\u001b[0m                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [44]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mprepare_and_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqnli_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqnli_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqnli_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemplate\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m <mask> \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [43]\u001b[0m, in \u001b[0;36mprepare_and_train\u001b[0;34m(train_df, val_df, test_df, template)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# train\u001b[39;00m\n\u001b[1;32m     44\u001b[0m trainer \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mTrainer(\n\u001b[1;32m     45\u001b[0m     logger \u001b[38;5;241m=\u001b[39m logger,\n\u001b[1;32m     46\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[early_stopping_callback,checkpoint_callback],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     49\u001b[0m     devices\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m     50\u001b[0m )\n\u001b[0;32m---> 51\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_module\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/local/scratch-3/yz709/anaconda3/envs/nlp-prompt-attack-env/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:696\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    678\u001b[0m \u001b[38;5;124;03mRuns the full optimization routine.\u001b[39;00m\n\u001b[1;32m    679\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    693\u001b[0m \u001b[38;5;124;03m    datamodule: An instance of :class:`~pytorch_lightning.core.datamodule.LightningDataModule`.\u001b[39;00m\n\u001b[1;32m    694\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    695\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m model\n\u001b[0;32m--> 696\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/local/scratch-3/yz709/anaconda3/envs/nlp-prompt-attack-env/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:650\u001b[0m, in \u001b[0;36mTrainer._call_and_handle_interrupt\u001b[0;34m(self, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    648\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    649\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 650\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    651\u001b[0m \u001b[38;5;66;03m# TODO(awaelchli): Unify both exceptions below, where `KeyboardError` doesn't re-raise\u001b[39;00m\n\u001b[1;32m    652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n",
      "File \u001b[0;32m/local/scratch-3/yz709/anaconda3/envs/nlp-prompt-attack-env/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:735\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    731\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m ckpt_path \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresume_from_checkpoint\n\u001b[1;32m    732\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__set_ckpt_path(\n\u001b[1;32m    733\u001b[0m     ckpt_path, model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    734\u001b[0m )\n\u001b[0;32m--> 735\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    737\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[1;32m    738\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/local/scratch-3/yz709/anaconda3/envs/nlp-prompt-attack-env/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1091\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   1088\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callback_connector\u001b[38;5;241m.\u001b[39m_attach_model_callbacks()\n\u001b[1;32m   1089\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callback_connector\u001b[38;5;241m.\u001b[39m_attach_model_logging_functions()\n\u001b[0;32m-> 1091\u001b[0m \u001b[43mverify_loop_configurations\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1093\u001b[0m \u001b[38;5;66;03m# hook\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m log\u001b[38;5;241m.\u001b[39mdetail(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: preparing data\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/local/scratch-3/yz709/anaconda3/envs/nlp-prompt-attack-env/lib/python3.10/site-packages/pytorch_lightning/trainer/configuration_validator.py:60\u001b[0m, in \u001b[0;36mverify_loop_configurations\u001b[0;34m(trainer)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# TODO: Delete CheckpointHooks off LightningDataModule in v1.8\u001b[39;00m\n\u001b[1;32m     59\u001b[0m _check_datamodule_checkpoint_hooks(trainer)\n\u001b[0;32m---> 60\u001b[0m \u001b[43m_check_setup_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/local/scratch-3/yz709/anaconda3/envs/nlp-prompt-attack-env/lib/python3.10/site-packages/pytorch_lightning/trainer/configuration_validator.py:308\u001b[0m, in \u001b[0;36m_check_setup_method\u001b[0;34m(trainer)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m [trainer\u001b[38;5;241m.\u001b[39mlightning_module, trainer\u001b[38;5;241m.\u001b[39mdatamodule] \u001b[38;5;241m+\u001b[39m trainer\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[1;32m    307\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_overridden(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msetup\u001b[39m\u001b[38;5;124m\"\u001b[39m, obj) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_param_in_hook_signature(obj\u001b[38;5;241m.\u001b[39msetup, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstage\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 308\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m MisconfigurationException(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.setup` does not have a `stage` argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mMisconfigurationException\u001b[0m: `QNLIDataModule.setup` does not have a `stage` argument."
     ]
    }
   ],
   "source": [
    "prepare_and_train(qnli_train, qnli_val, qnli_test, template = \" <mask> \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c72723",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95dec6bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b97383",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
