{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "019dcbd0",
   "metadata": {},
   "source": [
    "# Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3758580",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73980eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "411c59f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0ecc82",
   "metadata": {},
   "source": [
    "# Download datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e3dc71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnli_path = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "165f66cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72a50405da124122bdf20e782ceb21c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/5.14k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75d44b3c0b1c4cb7a89571a8168abce5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/2.88k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset multi_nli/default (download: 216.34 MiB, generated: 410.92 MiB, post-processed: Unknown size, total: 627.27 MiB) to /home/yz709/.cache/huggingface/datasets/multi_nli/default/0.0.0/591f72eb6263d1ab527561777936b199b714cda156d35716881158a2bd144f39...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d8252999db846078ac11b846fe78535",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/227M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/392702 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation_matched split:   0%|          | 0/9815 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation_mismatched split:   0%|          | 0/9832 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset multi_nli downloaded and prepared to /home/yz709/.cache/huggingface/datasets/multi_nli/default/0.0.0/591f72eb6263d1ab527561777936b199b714cda156d35716881158a2bd144f39. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2eed156ad51e4be48d76262731cbcff4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if mnli_path == None:\n",
    "    mnli = load_dataset(\"multi_nli\")\n",
    "    mnli_path = \"./datasets/mnli\"\n",
    "    mnli.save_to_disk(mnli_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3663e374",
   "metadata": {},
   "outputs": [],
   "source": [
    "qnli_path = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7915d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration SetFit--qnli-324fd6914ad1beff\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/SetFit--qnli to /home/yz709/.cache/huggingface/datasets/SetFit___json/SetFit--qnli-324fd6914ad1beff/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "457c3d7da87d422381c9c43b12fb755c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1e3250ad379448eb0b7f8f581e3abfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/31.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a636ba101fb453c933fc630aa5f3dd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/1.66M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efa954c89f0841d1a7b2dfabdd4ccc6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/1.66M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed6b5e699d1a4adda4e44f476ec9d0fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /home/yz709/.cache/huggingface/datasets/SetFit___json/SetFit--qnli-324fd6914ad1beff/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4c2bf833e69453d98b8069aafe2897f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if qnli_path == None:\n",
    "    qnli = load_dataset(\"SetFit/qnli\")\n",
    "    qnli_path = \"./datasets/qnli\"\n",
    "    qnli.save_to_disk(qnli_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe49be5",
   "metadata": {},
   "source": [
    "# Inspect datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b43448",
   "metadata": {},
   "source": [
    "## For qnli dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e00543fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text1', 'text2', 'label', 'idx', 'label_text'],\n",
       "        num_rows: 104743\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text1', 'text2', 'label', 'idx', 'label_text'],\n",
       "        num_rows: 5463\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text1', 'text2', 'label', 'idx', 'label_text'],\n",
       "        num_rows: 5463\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qnli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b79a1f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "qnli_train = qnli['train']\n",
    "qnli_test = qnli['test']\n",
    "qnli_val = qnli['validation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "41480f7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text1': ['What individual was responsible for law and maintaining order in the county?',\n",
       "  'How much of the gross domestic product was spent on public health in 2004?'],\n",
       " 'text2': ['He was the top civil and military leader of the commandery and handled defense, lawsuits, seasonal instructions to farmers and recommendations of nominees for office sent annually to the capital in a quota system first established by Emperor Wu.',\n",
       "  'Public expenditure health was at 8.9% of the GDP in 2004, whereas private expenditure was at 1.3%.'],\n",
       " 'label': [1, 0],\n",
       " 'idx': [104741, 104742],\n",
       " 'label_text': ['not entailment', 'entailment']}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# label 0 - entailment, label 1 - not entailment\n",
    "qnli_train[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5abbe76c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What individual was responsible for law and maintaining order in the county?',\n",
       " 'How much of the gross domestic product was spent on public health in 2004?']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qnli_train['text1'][-2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcea50ed",
   "metadata": {},
   "source": [
    "## For mnli dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "72e1d1e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['promptID', 'pairID', 'premise', 'premise_binary_parse', 'premise_parse', 'hypothesis', 'hypothesis_binary_parse', 'hypothesis_parse', 'genre', 'label'],\n",
       "        num_rows: 392702\n",
       "    })\n",
       "    validation_matched: Dataset({\n",
       "        features: ['promptID', 'pairID', 'premise', 'premise_binary_parse', 'premise_parse', 'hypothesis', 'hypothesis_binary_parse', 'hypothesis_parse', 'genre', 'label'],\n",
       "        num_rows: 9815\n",
       "    })\n",
       "    validation_mismatched: Dataset({\n",
       "        features: ['promptID', 'pairID', 'premise', 'premise_binary_parse', 'premise_parse', 'hypothesis', 'hypothesis_binary_parse', 'hypothesis_parse', 'genre', 'label'],\n",
       "        num_rows: 9832\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "260f7ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnli_train = mnli['train']\n",
    "mnli_val_match = mnli['validation_matched']\n",
    "mnli_val_mismatch = mnli['validation_mismatched']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "341ca12a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['promptID', 'pairID', 'premise', 'premise_binary_parse', 'premise_parse', 'hypothesis', 'hypothesis_binary_parse', 'hypothesis_parse', 'genre', 'label'],\n",
       "    num_rows: 392702\n",
       "})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnli_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7b7d8c18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'promptID': 31193,\n",
       " 'pairID': '31193n',\n",
       " 'premise': 'Conceptually cream skimming has two basic dimensions - product and geography.',\n",
       " 'premise_binary_parse': '( ( Conceptually ( cream skimming ) ) ( ( has ( ( ( two ( basic dimensions ) ) - ) ( ( product and ) geography ) ) ) . ) )',\n",
       " 'premise_parse': '(ROOT (S (NP (JJ Conceptually) (NN cream) (NN skimming)) (VP (VBZ has) (NP (NP (CD two) (JJ basic) (NNS dimensions)) (: -) (NP (NN product) (CC and) (NN geography)))) (. .)))',\n",
       " 'hypothesis': 'Product and geography are what make cream skimming work. ',\n",
       " 'hypothesis_binary_parse': '( ( ( Product and ) geography ) ( ( are ( what ( make ( cream ( skimming work ) ) ) ) ) . ) )',\n",
       " 'hypothesis_parse': '(ROOT (S (NP (NN Product) (CC and) (NN geography)) (VP (VBP are) (SBAR (WHNP (WP what)) (S (VP (VBP make) (NP (NP (NN cream)) (VP (VBG skimming) (NP (NN work)))))))) (. .)))',\n",
       " 'genre': 'government',\n",
       " 'label': 1}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnli_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "97c2a49b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'promptID': 37397,\n",
       " 'pairID': '37397e',\n",
       " 'premise': 'How do you know? All this is their information again.',\n",
       " 'premise_binary_parse': '( ( How ( ( ( do you ) know ) ? ) ) ( ( All this ) ( ( ( is ( their information ) ) again ) . ) ) )',\n",
       " 'premise_parse': '(ROOT (S (SBARQ (WHADVP (WRB How)) (SQ (VBP do) (NP (PRP you)) (VP (VB know))) (. ?)) (NP (PDT All) (DT this)) (VP (VBZ is) (NP (PRP$ their) (NN information)) (ADVP (RB again))) (. .)))',\n",
       " 'hypothesis': 'This information belongs to them.',\n",
       " 'hypothesis_binary_parse': '( ( This information ) ( ( belongs ( to them ) ) . ) )',\n",
       " 'hypothesis_parse': '(ROOT (S (NP (DT This) (NN information)) (VP (VBZ belongs) (PP (TO to) (NP (PRP them)))) (. .)))',\n",
       " 'genre': 'fiction',\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnli_train[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6412521",
   "metadata": {},
   "source": [
    "# Preprocess dataset QNLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d3f03942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# roberta-base or roberta-large\n",
    "PLM = \"roberta-base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "99464e61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf50895afffc4cfdb3b45b7d8d6ac49e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/501M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "model = AutoModel.from_pretrained(PLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f547cc8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2394bd0828441f485ce29cbb1c8b8a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/481 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20cd106c313c45a4ab82ddd8def367ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1758350b53e341748d0727122217b92f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53ad989f63424d888bfcd14929220e49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load tokeniser for the specific model\n",
    "tokeniser = AutoTokenizer.from_pretrained(PLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "847b2116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0, 45093,  2788,     7,  1296,   480, 19233,  6315,   646,  1001,\n",
      "          6747,   102,    12, 11070,   742,     2]])\n"
     ]
    }
   ],
   "source": [
    "# test the tokeniser\n",
    "test_input = \"Simple text to test -- tokenizer [roberta-base]\"\n",
    "tokenised_test_input = tokeniser.encode(test_input, return_tensors=\"pt\")\n",
    "print(tokenised_test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "92e7e328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s>', 'Simple', 'Ġtext', 'Ġto', 'Ġtest', 'Ġ--', 'Ġtoken', 'izer', 'Ġ[', 'ro', 'bert', 'a', '-', 'base', ']', '</s>']\n"
     ]
    }
   ],
   "source": [
    "test_token_id_to_text = tokeniser.convert_ids_to_tokens(tokeniser.encode(test_input))\n",
    "print(test_token_id_to_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cb65310c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the model\n",
    "test_output = model(tokenised_test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9e6b4cac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 16, 768]), torch.Size([1, 768]))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "First output:\n",
    "# (1,16,768): batch_size * #tokens * embedding_size_defined_by_model\n",
    "# our input is one sentence with 16 tokens\n",
    "Second output - pooler output, the embedding result of the first token of the sequence <s>\n",
    "\"\"\"\n",
    "test_output[0].size(), test_output[1].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "873e3e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def manual_prompt(questions, answers, template):\n",
    "    prompt = answers + template + questions\n",
    "    print(prompt)\n",
    "    prompt_token_id = tokeniser(prompt, return_tensors=\"pt\").input_ids\n",
    "    prompt_id_to_text = tokeniser.convert_ids_to_tokens(prompt_token_id[0])\n",
    "    mask_token_pos = prompt_id_to_text.index(tokeniser.mask_token)\n",
    "    return prompt_token_id, mask_token_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "cdb15512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unlike the two seasons before it and most of the seasons that followed, Digimon Tamers takes a darker and more realistic approach to its story featuring Digimon who do not reincarnate after their deaths and more complex character development in the original Japanese. This is <mask> to the following sentence: When did the third Digimon series begin?\n"
     ]
    }
   ],
   "source": [
    "manual_template = \" This is <mask> to the following sentence: \"\n",
    "prompt_token_id, mask_token_pos = manual_prompt(qnli_train[0]['text1'], qnli_train[0]['text2'], manual_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a1941df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 68, 768])\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = model(prompt_token_id)[0]\n",
    "print(predictions.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a096df1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "values, indices = torch.sort(predictions[0, mask_token_pos], descending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "dce1cb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = list(zip(tokeniser.convert_ids_to_tokens(indices), values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e2d52a99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Ġreal', tensor(10.3457))"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "e7750573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qnli_train[0]['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c72723",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
